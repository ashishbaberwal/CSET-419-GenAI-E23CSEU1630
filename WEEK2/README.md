# Week 2 (21-01-2026)

- Folder: [Week_02](.)

## Summary

This week's project focuses on building and training a Generative Adversarial Network (GAN) to generate synthetic images of handwritten digits that resemble the MNIST dataset. The quality of these generated images is then evaluated using a pre-trained LeNet-5 classifier.

## Key Features:

- **Dynamic GAN Configuration:** The GAN's hyperparameters, such as the number of epochs, batch size, and noise dimension, can be dynamically configured by the user, allowing for experimentation and fine-tuning.

- **Data Loading and Preprocessing:** The MNIST dataset is loaded and preprocessed, with images normalized to a range of `[-1, 1]` to match the generator's output activation function (`tanh`).

- **Generator and Discriminator Architecture:**
  - The **Generator** uses `Conv2DTranspose` layers to upsample a random noise vector into a `28x28` grayscale image.
  - The **Discriminator** is a standard Convolutional Neural Network (CNN) designed to classify images as either real (from the MNIST dataset) or fake (generated by the generator).

- **GAN Training:** The GAN is trained in a loop where the generator and discriminator are pitted against each other. The generator learns to produce more realistic images, while the discriminator gets better at distinguishing real from fake.

- **Image Generation and Classification:** After training, the generator produces a set of synthetic digit images. These images are then classified by a pre-trained LeNet-5 model, and the results are used to sort the images into folders corresponding to their predicted labels (0-9).

- **Performance Evaluation:** The accuracy of the LeNet-5 classifier on the GAN-generated images is calculated to assess the quality and realism of the synthetic digits. A detailed breakdown of predictions is also provided to offer insights into the classifier's performance on individual images.
